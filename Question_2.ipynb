{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f36a8e0",
      "metadata": {
        "id": "1f36a8e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c81e1acb-ecdd-49a1-decf-4d9a82926ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.6.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWvZVHHsT3Vr",
        "outputId": "82347c85-b808-4510-e754-05625ecaaa5e"
      },
      "id": "hWvZVHHsT3Vr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from wikipedia-api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipediaapi"
      ],
      "metadata": {
        "id": "HtHC9RaAT5WS"
      },
      "id": "HtHC9RaAT5WS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYDpdc8zUhNC",
        "outputId": "e83dc284-6c21-4b95-b080-7f6645d89a0c"
      },
      "id": "XYDpdc8zUhNC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.5)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.77)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohnay9x0Vt1j",
        "outputId": "b1f5a641-dd6f-44bc-cfa7-790ffcb2596e"
      },
      "id": "Ohnay9x0Vt1j",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.5)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.77)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (2.7.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (2.18.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.4 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56507ef9",
      "metadata": {
        "id": "56507ef9"
      },
      "source": [
        "# Searching Generative Artificial intelligence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93dcba56",
      "metadata": {
        "id": "93dcba56",
        "outputId": "3a1d4c49-2920-4a76-bfea-9feed53a660a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n"
          ]
        }
      ],
      "source": [
        "loader = WikipediaLoader(\"Generative Artificial Intelligence\")\n",
        "\n",
        "# Load the documents\n",
        "documents = loader.load()\n",
        "\n",
        "# Print the number of documents loaded\n",
        "print(len(documents))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ca84dc1",
      "metadata": {
        "id": "0ca84dc1",
        "outputId": "f730cb94-7a60-45ac-c584-9a230b474f42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='Generative artificial intelligence (generative AI, GenAI, or GAI) is artificial intelligence capable of generating text, images, videos, or other data using generative models, often in response to prompts. Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.\\nImprovements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the early 2020s. These include chatbots such as ChatGPT, Copilot, Gemini and LLaMA, text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney and DALL-E, and text-to-video AI generators such as Sora. Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.\\n\\n\\n== History ==\\n\\nThe academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since. Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity. The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music. The tradition of creative automatons has flourished throughout history, exemplified by Maillardet\\'s automaton created in the early 1800s.\\nArtificial Intelligence is an idea that has been captivating society since the mid-20th century. It began with science fiction familiarizing the world with the concept but the idea was not fully seen in the scientific manner until Alan Turing, a polymath, was curious about the feasibility of the concept. Turing\\'s groundbreaking 1950 paper, \"Computing Machinery and Intelligence,\" posed fundamental questions about machine reasoning similar to human intelligence, significantly contributing to the conceptual groundwork of AI. The development of AI was not very rapid at first because of the high costs and the fact that computers were not able to store commands. This changed during the 1956 Dartmouth Summer Research Project on AI where there was an inspiring call for AI research, setting the precedent for two decades of rapid advancements in the field.\\nSince the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.\\nMarkov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906, and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.\\nThe field of machine learning often uses statistical models, including generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image classification, speech reco', metadata={'title': 'Generative artificial intelligence', 'summary': 'Generative artificial intelligence (generative AI, GenAI, or GAI) is artificial intelligence capable of generating text, images, videos, or other data using generative models, often in response to prompts. Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.\\nImprovements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the early 2020s. These include chatbots such as ChatGPT, Copilot, Gemini and LLaMA, text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney and DALL-E, and text-to-video AI generators such as Sora. Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.', 'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence'}),\n",
              " Document(page_content='In the 2020s, the rapid advancement of deep learning-based generative artificial intelligence models are raising questions about whether copyright infringement occurs when the generative AI is trained or used. This includes text-to-image models such as Stable Diffusion and large language models such as ChatGPT. As of 2023, there are several pending U.S. lawsuits challenging the use of copyrighted data to train AI models, with defendants arguing that this falls under fair use.\\nPopular deep learning models are trained on mass amounts of media scraped from the Internet, often utilizing copyrighted material. When assembling training data, the sourcing of copyrighted works may infringe on the copyright holder\\'s exclusive right to control reproduction, unless covered by exceptions in relevant copyright laws. Additionally, using a model\\'s outputs might violate copyright, and the model creator could be accused of vicarious liability and held responsible for that copyright infringement.\\n\\n\\n== Copyright status of AI-generated works ==\\n\\nSince most legal jurisdictions only grant copyright to original works of authorship by human authors, the definition of \"originality\" is central to the copyright status of AI-generated works.\\n\\n\\n=== United States ===\\nIn the U.S., the Copyright Act protects \"original works of authorship\". The U.S. Copyright Office has interpreted this as being limited to works \"created by a human being\", declining to grant copyright to works generated without human intervention. Some have suggested that certain AI generations might be copyrightable in the U.S. and similar jurisdictions if it can be shown that the human who ran the AI program exercised sufficient originality in selecting the inputs to the AI or editing the AI\\'s output.\\nProponents of this view suggest that an AI model may be viewed as merely a tool (akin to a pen or a camera) used by its human operator to express their creative vision. For example, proponents argue that if the standard of originality can be satisfied by an artist clicking the shutter button on a camera, then perhaps artists using generative AI should get similar deference, especially if they go through multiple rounds of revision to refine their prompts to the AI. Other proponents argue that the Copyright Office is not taking a technology neutral  approach to the use of AI or algorithmic tools. For other creative expressions (music, photography, writing) the test is effectively whether there is de minimis, or limited human creativity. For works using AI tools, the Copyright Office has made the test a different one i.e. whether there is no more than de minimis technological involvement.\\n\\nThis difference in approach can be seen in the recent decision in respect of a registration claim by Jason Matthew Allen for his work Théâtre D\\'opéra Spatial created using Midjourney and an upscaling tool. The Copyright Office stated: The Board finds that the Work contains more than a de minimis amount of content generated by artificial intelligence (\"AI\"), and this content must therefore be disclaimed in an application for registration. Because Mr. Allen is unwilling to disclaim the AI-generated material, the Work cannot be registered as submitted.\\nAs AI is increasingly used to generate literature, music, and other forms of art, the U.S. Copyright Office has released new guidance emphasizing whether works, including materials generated by artificial intelligence, exhibit a \\'mechanical reproduction\\' nature or are the \\'manifestation of the author\\'s own creative conception\\'. The U.S. Copyright Office published a Rule in March 2023 on a range of issues related to the use of AI, where they stated:\\n\\n...because the Office receives roughly half a million applications for registration each year, it sees new trends in registration activity that may require modifying or expanding the information required to be disclosed on an application.\\nOne such recent development is the use of sophisticated artificial intelligence (\"A', metadata={'title': 'Artificial intelligence and copyright', 'summary': \"In the 2020s, the rapid advancement of deep learning-based generative artificial intelligence models are raising questions about whether copyright infringement occurs when the generative AI is trained or used. This includes text-to-image models such as Stable Diffusion and large language models such as ChatGPT. As of 2023, there are several pending U.S. lawsuits challenging the use of copyrighted data to train AI models, with defendants arguing that this falls under fair use.\\nPopular deep learning models are trained on mass amounts of media scraped from the Internet, often utilizing copyrighted material. When assembling training data, the sourcing of copyrighted works may infringe on the copyright holder's exclusive right to control reproduction, unless covered by exceptions in relevant copyright laws. Additionally, using a model's outputs might violate copyright, and the model creator could be accused of vicarious liability and held responsible for that copyright infringement.\", 'source': 'https://en.wikipedia.org/wiki/Artificial_intelligence_and_copyright'}),\n",
              " Document(page_content='Artificial intelligence art is any visual artwork created through the use of an artificial intelligence (AI) program.   \\nArtists began to create artificial intelligence art in the mid to late 20th century, when the discipline was founded. Throughout its history, artificial intelligence art has raised many philosophical concerns related to the human mind, artificial beings, and what can be considered art in a human–AI collaboration. Since the 20th century, artists have used AI to create art, some of which has been exhibited in museums and won awards.   \\nThe increased availability of AI art tools to the general public in the 2020s AI boom provided opportunities for creating AI generated images outside of academia and professional artists. Commentary about AI art in the 2020s has often focused on issues related to copyright, deception, defamation, and its impact on more traditional artists, including technological unemployment.\\n\\n\\n== History ==\\n\\n\\n=== Early history ===\\n\\nThe concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music. The tradition of creative automatons has been throughout history, such as Maillardet\\'s automaton, created in the early 1800s.\\nThe academic discipline of artificial intelligence was founded at a research workshop at Dartmouth College in 1956, and has experienced several waves of advancement and optimism in the decades since. Since its founding, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction, and philosophy since antiquity.\\n\\n\\n=== 1950s to 2000s: Early implementations ===\\nSince the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. These works were sometimes referred to as algorithmic art, computer art, digital art, or new media.\\nOne of the first significant AI art systems was AARON, developed by Harold Cohen beginning in the late 1960s at the University of California at San Diego. AARON uses a symbolic rule-based approach to generate technical images in the era of GOFAI programming. Cohen developed AARON with the goal of being able to code the act of drawing. In its primitive form, AARON created simple black-and-white drawings. Cohen would later finish the drawings by painting them. Throughout the years, he also began to develop a way for AARON to also paint. Cohen designed AARON to paint using special brushes and dyes that were chosen by the program itself without mediation from Cohen. AARON was exhibited in 1972 at the Los Angeles County Museum of Art. From 1973 to 1975, Cohen refined AARON during a residency at the Artificial Intelligence Laboratory at Stanford University.\\nIn both 1991 and 1992, Karl Sims won the Golden Nica award at Prix Ars Electronica for his 3D AI animated videos using artificial evolution. In 2001, Scott Draves won the Fundacion Telefonica Life 4.0 prize for Electric Sheep, which used AI to create an infinite animation by learning from its audience. In 2009, Eric Millikin won the Pulitzer Prize along with several other awards for his artificial intelligence art that was critical of government corruption in Detroit and resulted in the city\\'s mayor being sent to jail.\\n\\n\\n=== 2010s: Deep learning ===\\n\\nIn 2014, Ian Goodfellow and colleagues at Université de Montréal developed the generative adversarial network (GAN), a type of deep neural network capable of learning to mimic the statistical distribution of input data such as images. The GAN uses a \"generator\" to create new images and a \"discriminator\" to decide which created images are considered successful. Unlike previous algorithmic art which followed hand-coded rules, generative adv', metadata={'title': 'Artificial intelligence art', 'summary': 'Artificial intelligence art is any visual artwork created through the use of an artificial intelligence (AI) program.   \\nArtists began to create artificial intelligence art in the mid to late 20th century, when the discipline was founded. Throughout its history, artificial intelligence art has raised many philosophical concerns related to the human mind, artificial beings, and what can be considered art in a human–AI collaboration. Since the 20th century, artists have used AI to create art, some of which has been exhibited in museums and won awards.   \\nThe increased availability of AI art tools to the general public in the 2020s AI boom provided opportunities for creating AI generated images outside of academia and professional artists. Commentary about AI art in the 2020s has often focused on issues related to copyright, deception, defamation, and its impact on more traditional artists, including technological unemployment.', 'source': 'https://en.wikipedia.org/wiki/Artificial_intelligence_art'}),\n",
              " Document(page_content='The Artificial Intelligence Act (AI Act) is a European Union regulation concerning artificial intelligence (AI).\\nIt establishes a common regulatory and legal framework for AI within the European Union (EU). Proposed by the European Commission on 21 April 2021, it passed the European Parliament on 13 March 2024, and was unanimously approved by the EU Council on 21 May 2024. The Act also creates a European Artificial Intelligence Board to promote national cooperation and ensure compliance with the regulation. Like the EU\\'s General Data Protection Regulation, the Act can apply extraterritorially to providers from outside the EU if they have users within the EU.\\nIt covers all types of AI across a broad range of sectors, with exceptions for AI systems used solely for military, national security, research and non-professional purposes. As a piece of product regulation, it does not confer rights on individuals, but regulates the providers of AI systems and entities using AI in a professional context. The draft Act was revised to address the rise in popularity of generative artificial intelligence systems, such as ChatGPT, whose general-purpose capabilities did not fit the main framework. More restrictive regulations are planned for powerful generative AI systems with systemic impact.\\nThe Act classifies non-exempted AI applications by their risk of causing harm. There are four levels—unacceptable, high, limited, minimal—plus an additional category for general-purpose AI. Applications with unacceptable risks are banned. High-risk applications must comply with security, transparency and quality obligations, and undergo conformity assessments. Limited-risk applications only have transparency obligations, while minimal-risk applications are not regulated. For general-purpose AI, transparency requirements are imposed, with additional evaluations for high-capability models.\\n\\n\\n== Provisions ==\\n\\n\\n=== Risk categories ===\\nThere are different risk categories depending on the type of application, with a specific category dedicated to general-purpose generative AI:\\n\\nUnacceptable risk – AI applications in this category are banned, except for specific exemptions. When no exemption applies, this includes AI applications that manipulate human behaviour, those that use real-time remote biometric identification (such as facial recognition) in public spaces, and those used for social scoring (ranking individuals based on their personal characteristics, socio-economic status or behaviour).\\nHigh-risk – AI applications that are expected to pose significant threats to health, safety, or the fundamental rights of persons. Notably, AI systems used in health, education, recruitment, critical infrastructure management, law enforcement or justice. They are subject to quality, transparency, human oversight and safety obligations, and in some cases require a \"Fundamental Rights Impact Assessment\" before deployment. They must be evaluated both before they are placed on the market and throughout their life cycle. The list of high-risk applications can be expanded over time, without the need to modify the AI Act itself.\\nGeneral-purpose AI – Added in 2023, this category includes in particular foundation models like ChatGPT. They are subject to transparency requirements. High-impact general-purpose AI systems which could pose systemic risks (notably those trained using a computational capability exceeding 1025 FLOPS) must also undergo a thorough evaluation process.\\nLimited risk – AI systems in this category have transparency obligations, ensuring users are informed that they are interacting with an AI system and allowing them to make informed choices. This category includes, for example, AI applications that make it possible to generate or manipulate images, sound, or videos (like deepfakes). In this category, free models that are open source (i.e., whose parameters are publicly available) are not regulated, with some exceptions.\\nMinimal risk – This category includes, f', metadata={'title': 'Artificial Intelligence Act', 'summary': \"The Artificial Intelligence Act (AI Act) is a European Union regulation concerning artificial intelligence (AI).\\nIt establishes a common regulatory and legal framework for AI within the European Union (EU). Proposed by the European Commission on 21 April 2021, it passed the European Parliament on 13 March 2024, and was unanimously approved by the EU Council on 21 May 2024. The Act also creates a European Artificial Intelligence Board to promote national cooperation and ensure compliance with the regulation. Like the EU's General Data Protection Regulation, the Act can apply extraterritorially to providers from outside the EU if they have users within the EU.\\nIt covers all types of AI across a broad range of sectors, with exceptions for AI systems used solely for military, national security, research and non-professional purposes. As a piece of product regulation, it does not confer rights on individuals, but regulates the providers of AI systems and entities using AI in a professional context. The draft Act was revised to address the rise in popularity of generative artificial intelligence systems, such as ChatGPT, whose general-purpose capabilities did not fit the main framework. More restrictive regulations are planned for powerful generative AI systems with systemic impact.\\nThe Act classifies non-exempted AI applications by their risk of causing harm. There are four levels—unacceptable, high, limited, minimal—plus an additional category for general-purpose AI. Applications with unacceptable risks are banned. High-risk applications must comply with security, transparency and quality obligations, and undergo conformity assessments. Limited-risk applications only have transparency obligations, while minimal-risk applications are not regulated. For general-purpose AI, transparency requirements are imposed, with additional evaluations for high-capability models.\\n\\n\", 'source': 'https://en.wikipedia.org/wiki/Artificial_Intelligence_Act'}),\n",
              " Document(page_content='Generative pre-trained transformers (GPT) are a type of large language model (LLM) and a prominent framework for generative artificial intelligence. They are artificial neural networks that are used in natural language processing tasks. GPTs are based on the transformer architecture, pre-trained on large data sets of unlabelled text, and able to generate novel human-like content. As of 2023, most LLMs have these characteristics and are sometimes referred to broadly as GPTs.\\nThe first GPT was introduced in 2018 by OpenAI. OpenAI has released very influential GPT foundation models that have been sequentially numbered, to comprise its \"GPT-n\" series. Each of these was significantly more capable than the previous, due to increased size (number of trainable parameters) and training. The most recent of these, GPT-4, was released in March 2023. Such models have been the basis for their more task-specific GPT systems, including models fine-tuned for instruction following—which in turn power the ChatGPT chatbot service. \\nThe term \"GPT\" is also used in the names and descriptions of such models developed by others. For example, other GPT foundation models include a series of models created by EleutherAI, and seven models created by Cerebras in 2023. Also, companies in different industries have developed task-specific GPTs in their respective fields, such as Salesforce\\'s \"EinsteinGPT\" (for CRM) and Bloomberg\\'s \"BloombergGPT\" (for finance).\\n\\n\\n== History ==\\n\\n\\n=== Initial developments ===\\nGenerative pretraining (GP) was a long-established concept in machine learning applications. It was originally used as a form of semi-supervised learning, as the model is trained first on an unlabelled dataset (pretraining step) by learning to generate datapoints in the dataset, and then it is trained to classify a labelled dataset.\\nWhile the unnormalized linear transformer dates back to 1992, the modern transformer architecture was not available until 2017 when it was published by researchers at Google in a paper \"Attention Is All You Need\". That development led to the emergence of large language models such as BERT in 2018 which was a pre-trained transformer (PT) but not designed to be generative (BERT was an \"encoder-only\" model). Also around that time, in 2018, OpenAI published its article entitled \"Improving Language Understanding by Generative Pre-Training\", in which it introduced the first generative pre-trained transformer (GPT) system (\"GPT-1\"). \\nPrior to transformer-based architectures, the best-performing neural NLP (natural language processing) models commonly employed supervised learning from large amounts of manually-labeled data. The reliance on supervised learning limited their use on datasets that were not well-annotated, and also made it prohibitively expensive and time-consuming to train extremely large language models.\\nThe semi-supervised approach OpenAI employed to make a large-scale generative system—and was first to do with a transformer model—involved two stages: an unsupervised generative \"pretraining\" stage to set initial parameters using a language modeling objective, and a supervised discriminative \"fine-tuning\" stage to adapt these parameters to a target task.\\n\\n\\n=== Later developments ===\\nRegarding more recent GPT foundation models, OpenAI published its first versions of GPT-3 in July 2020. There were three models, with 1B, 6.7B, 175B parameters, respectively named babbage, curie, and davinci (giving initials B, C, and D).\\nIn July 2021, OpenAI published Codex, a task-specific GPT model targeted for programming applications. This was developed by fine-tuning a 12B parameter version of GPT-3 (different from previous GPT-3 models) using code from GitHub.\\nIn March 2022, OpenAI published two versions of GPT-3 that were fine-tuned for instruction-following (instruction-tuned), named davinci-instruct-beta (175B) and text-davinci-001, and then started beta testing code-davinci-002. text-davinci-002 was instruction-tuned from code-davinc', metadata={'title': 'Generative pre-trained transformer', 'summary': 'Generative pre-trained transformers (GPT) are a type of large language model (LLM) and a prominent framework for generative artificial intelligence. They are artificial neural networks that are used in natural language processing tasks. GPTs are based on the transformer architecture, pre-trained on large data sets of unlabelled text, and able to generate novel human-like content. As of 2023, most LLMs have these characteristics and are sometimes referred to broadly as GPTs.\\nThe first GPT was introduced in 2018 by OpenAI. OpenAI has released very influential GPT foundation models that have been sequentially numbered, to comprise its \"GPT-n\" series. Each of these was significantly more capable than the previous, due to increased size (number of trainable parameters) and training. The most recent of these, GPT-4, was released in March 2023. Such models have been the basis for their more task-specific GPT systems, including models fine-tuned for instruction following—which in turn power the ChatGPT chatbot service. \\nThe term \"GPT\" is also used in the names and descriptions of such models developed by others. For example, other GPT foundation models include a series of models created by EleutherAI, and seven models created by Cerebras in 2023. Also, companies in different industries have developed task-specific GPTs in their respective fields, such as Salesforce\\'s \"EinsteinGPT\" (for CRM) and Bloomberg\\'s \"BloombergGPT\" (for finance).', 'source': 'https://en.wikipedia.org/wiki/Generative_pre-trained_transformer'}),\n",
              " Document(page_content='A chatbot (originally chatterbot) is a software application or web interface that is designed to mimic human conversation through text or voice interactions. Modern chatbots are typically online and use generative artificial intelligence systems that are capable of maintaining a conversation with a user in natural language and simulating the way a human would behave as a conversational partner. Such chatbots often use deep learning and natural language processing, but simpler chatbots have existed for decades.\\nSince late 2022, the field has gained widespread attention due to the popularity of OpenAI\\'s ChatGPT, followed by alternatives such as Microsoft\\'s Copilot and Google\\'s Gemini. Such examples reflect the recent practice of basing such products upon broad foundational large language models, such as GPT-4 or the Gemini language model, that get fine-tuned so as to target specific tasks or applications (i.e., simulating human conversation, in the case of chatbots). Chatbots can also be designed or customized to further target even more specific situations and/or particular subject-matter domains.\\nA major area where chatbots have long been used is in customer service and support, with various sorts of virtual assistants. Companies spanning a wide range of industries have begun using the latest generative artificial intelligence technologies to power more advanced developments in such areas.\\nAs chatbots work by predicting responses rather than knowing the meaning of their responses, this means they can produce coherent-sounding but inaccurate or fabricated content, referred to as ‘hallucinations’. When humans use and apply chatbot content contaminated with hallucinations, this results in ‘botshit’. Given the increasing adoption and use of chatbots for generating content, there are concerns that this technology will significantly reduce the cost it takes humans to generate, spread and consume botshit.\\n\\n\\n== Background ==\\nIn 1950, Alan Turing\\'s famous article \"Computing Machinery and Intelligence\" was published, which proposed what is now called the Turing test as a criterion of intelligence. This criterion depends on the ability of a computer program to impersonate a human in a real-time written conversation with a human judge to the extent that the judge is unable to distinguish reliably—on the basis of the conversational content alone—between the program and a real human. The notoriety of Turing\\'s proposed test stimulated great interest in Joseph Weizenbaum\\'s program ELIZA, published in 1966, which seemed to be able to fool users into believing that they were conversing with a real human. However Weizenbaum himself did not claim that ELIZA was genuinely intelligent, and the introduction to his paper presented it more as a debunking exercise:\\n\\nIn artificial intelligence, machines are made to behave in wondrous ways, often sufficient to dazzle even the most experienced observer. But once a particular program is unmasked, once its inner workings are explained, its magic crumbles away; it stands revealed as a mere collection of procedures. The observer says to himself \"I could have written that\". With that thought, he moves the program in question from the shelf marked \"intelligent\", to that reserved for curios. The object of this paper is to cause just such a re-evaluation of the program about to be \"explained\". Few programs ever needed it more.\\nELIZA\\'s key method of operation (copied by chatbot designers ever since) involves the recognition of clue words or phrases in the input, and the output of the corresponding pre-prepared or pre-programmed responses that can move the conversation forward in an apparently meaningful way (e.g. by responding to any input that contains the word \\'MOTHER\\' with \\'TELL ME MORE ABOUT YOUR FAMILY\\'). Thus an illusion of understanding is generated, even though the processing involved has been merely superficial. ELIZA showed that such an illusion is surprisingly easy to generate because human judges are s', metadata={'title': 'Chatbot', 'summary': \"A chatbot (originally chatterbot) is a software application or web interface that is designed to mimic human conversation through text or voice interactions. Modern chatbots are typically online and use generative artificial intelligence systems that are capable of maintaining a conversation with a user in natural language and simulating the way a human would behave as a conversational partner. Such chatbots often use deep learning and natural language processing, but simpler chatbots have existed for decades.\\nSince late 2022, the field has gained widespread attention due to the popularity of OpenAI's ChatGPT, followed by alternatives such as Microsoft's Copilot and Google's Gemini. Such examples reflect the recent practice of basing such products upon broad foundational large language models, such as GPT-4 or the Gemini language model, that get fine-tuned so as to target specific tasks or applications (i.e., simulating human conversation, in the case of chatbots). Chatbots can also be designed or customized to further target even more specific situations and/or particular subject-matter domains.\\nA major area where chatbots have long been used is in customer service and support, with various sorts of virtual assistants. Companies spanning a wide range of industries have begun using the latest generative artificial intelligence technologies to power more advanced developments in such areas.\\nAs chatbots work by predicting responses rather than knowing the meaning of their responses, this means they can produce coherent-sounding but inaccurate or fabricated content, referred to as ‘hallucinations’. When humans use and apply chatbot content contaminated with hallucinations, this results in ‘botshit’. Given the increasing adoption and use of chatbots for generating content, there are concerns that this technology will significantly reduce the cost it takes humans to generate, spread and consume botshit.\", 'source': 'https://en.wikipedia.org/wiki/Chatbot'}),\n",
              " Document(page_content='In the field of artificial intelligence (AI), a hallucination or artificial hallucination (also called bullshitting, confabulation or delusion) is a response generated by AI which contains false or misleading information presented as fact. This term draws a loose analogy with human psychology, where hallucination typically involves false percepts. However, there is a key difference: AI hallucination is associated with unjustified responses or beliefs rather than perceptual experiences.\\nFor example, a chatbot powered by large language models (LLMs), like ChatGPT, may embed plausible-sounding random falsehoods within its generated content. Researchers have recognized this issue, and by 2023, analysts estimated that chatbots hallucinate as much as 27% of the time, with factual errors present in 46% of their responses. Detecting and mitigating these hallucinations pose significant challenges for practical deployment and reliability of LLMs in real-world scenarios. Some researchers believe the specific term \"AI hallucination\" unreasonably anthropomorphizes computers.\\n\\n\\n== Origin of the term ==\\nIn the early 2000s, the term \"hallucination\" was used in computer vision  with a positive connotation to describe the process of adding detail to an image. For example, the task of generating high-resolution face images from low-resolution inputs is called face hallucination.\\nIn the late 2010s, the term underwent a semantic shift to signify the generation of factually incorrect or misleading outputs by AI systems in tasks like translation or object detection. For example, in 2017, Google researchers used the term to describe the responses generated by neural machine translation (NMT) models when they are not related to the source text, and in 2018, the term was used in computer vision to describe instances where non-existent objects are erroneously detected because of adversarial attacks.\\nThe term \"hallucinations\" in AI gained wider recognition during the AI boom, alongside the rollout of widely used chatbots based on large language models (LLMs). In July 2021, Meta warned during its release of BlenderBot 2 that the system is prone to \"hallucinations\", which Meta defined as \"confident statements that are not true\". Following OpenAI\\'s ChatGPT release in beta-version in November 2022, some users complained that such chatbots often seem to pointlessly embed plausible-sounding random falsehoods within their generated content. Many news outlets, including The New York Times, started to use the term \"hallucinations\" to describe these model\\'s occasionally incorrect or inconsistent responses.\\nIn 2023, some dictionaries updated their definition of hallucination to include a new meaning specific to the field of AI.\\n\\n\\n== In natural language processing ==\\n\\nIn natural language processing, a hallucination is often defined as \"generated content that appears factual but is ungrounded\". There are different ways to categorize hallucinations.  Depending on whether the output contradicts the source or cannot be verified from the source, they are divided into intrinsic and extrinsic, respectively. Depending on whether the output contradicts the prompt or not they could be divided into closed-domain and open-domain respectively.\\n\\n\\n=== Causes ===\\nThere are several reasons for natural language models to hallucinate data.\\n\\n\\n==== Hallucination from data ====\\nThe main cause of hallucination from data is source-reference divergence. This divergence happens 1) as an artifact of heuristic data collection or 2) due to the nature of some NLG tasks that inevitably contain such divergence. When a model is trained on data with source-reference (target) divergence, the model can be encouraged to generate text that is not necessarily grounded and not faithful to the provided source.\\n\\n\\n==== Hallucination from modeling ====\\nHallucination was shown to be a statistically inevitable byproduct of any imperfect generative model that is trained to maximize training likelihood, such as G', metadata={'title': 'Hallucination (artificial intelligence)', 'summary': 'In the field of artificial intelligence (AI), a hallucination or artificial hallucination (also called bullshitting, confabulation or delusion) is a response generated by AI which contains false or misleading information presented as fact. This term draws a loose analogy with human psychology, where hallucination typically involves false percepts. However, there is a key difference: AI hallucination is associated with unjustified responses or beliefs rather than perceptual experiences.\\nFor example, a chatbot powered by large language models (LLMs), like ChatGPT, may embed plausible-sounding random falsehoods within its generated content. Researchers have recognized this issue, and by 2023, analysts estimated that chatbots hallucinate as much as 27% of the time, with factual errors present in 46% of their responses. Detecting and mitigating these hallucinations pose significant challenges for practical deployment and reliability of LLMs in real-world scenarios. Some researchers believe the specific term \"AI hallucination\" unreasonably anthropomorphizes computers.', 'source': 'https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)'}),\n",
              " Document(page_content=\"Artificial intelligence in mental health is the application of artificial intelligence (AI), computational technologies and algorithms to supplement the understanding, diagnosis, and treatment of mental health disorders. AI is becoming a ubiquitous force in everyday life which can be seen through frequent operation of models like ChatGPT. Utilizing AI in the realm of mental health signifies a form of digital healthcare, in which, the goal is to increase accessibility in a world where mental health is becoming a growing concern. Prospective ideas involving AI in mental health include identification and diagnosis of mental disorders, explication of electronic health records, creation of personalized treatment plans, and predictive analytics for suicide prevention.  Learning how to apply AI in healthcare proves to be a difficult task with many challenges, thus it remains rarely used as efforts to bridge gaps are deliberated. \\n\\n\\n== Background ==\\nIn 2019, 1 in every 8 people, or 970 million people around the world were living with a mental disorder, with anxiety and depressive disorders the most common. In 2020, the number of people living with anxiety and depressive disorders rose significantly because of the COVID-19 pandemic. Additionally, the prevalence of mental health and addiction disorders exhibits a nearly equal distribution across genders, emphasizing the widespread nature of the issue.\\nThe use of AI in mental health aims to support responsive and sustainable interventions against the global challenge posed by mental health disorders. Some issues common to the mental health industry are provider shortages, inefficient diagnoses, and ineffective treatments. The AI industry sees a market in healthcare, with a focus on mental health applications, which are projected to grow substantially, from $5 billion in 2020 to an estimated $45 billion by 2026. This growth indicates a growing interest in AI's ability to address critical challenges in mental healthcare provision through the development and implementation of innovative solutions.\\n\\n\\n== Types of AI in mental health ==\\nAs of 2020, there was no Food and Drug Administration (FDA) approval for AI in the field of Psychiatry. There are two components of AI that are currently widely available for multiple applications, they are Machine learning (ML) and Natural language processing (NLP).\\n\\n\\n=== Machine learning ===\\nMachine learning is a way for a computer to learn from large datasets presented to it, without explicit instructions. It requires structured databases; unlike scientific research which begins with a hypothesis, ML begins by looking at the data and finding its own hypothesis based on the patterns that it detects. It then creates algorithms to be able to predict new information, based on the created algorithm and pattern that it was able to generate from the original dataset. This model of AI is data driven, as it requires a huge amount of structured data—an obstacle in the field of psychiatry—with a lot of its patient encounters being based on interview and storytelling on the part of the patient. Due to these limitations, some researchers have adopted a different method of developing ML models, a process named transfer learning, to be used in psychiatry based on trained models from different fields.\\nTransfer learning was used by researchers to develop a modified algorithm to detect alcoholism vs. non-alcoholism, and on another occasion, the same method was used to detect the signs of post-traumatic stress disorder.\\n\\n\\n=== Natural language processing ===\\nOne of the obstacles for AI is finding or creating an organized dataset to train and develop a useful algorithm. Natural language processing can be used to create such a dataset. NLP is a way for a computer to analyze text and speech, process semantic and lexical representations, as well as recognize speech and optical characters in data. This is crucial because many of the diagnoses and DSM-5 mental health disorders are di\", metadata={'title': 'Artificial intelligence in mental health', 'summary': 'Artificial intelligence in mental health is the application of artificial intelligence (AI), computational technologies and algorithms to supplement the understanding, diagnosis, and treatment of mental health disorders. AI is becoming a ubiquitous force in everyday life which can be seen through frequent operation of models like ChatGPT. Utilizing AI in the realm of mental health signifies a form of digital healthcare, in which, the goal is to increase accessibility in a world where mental health is becoming a growing concern. Prospective ideas involving AI in mental health include identification and diagnosis of mental disorders, explication of electronic health records, creation of personalized treatment plans, and predictive analytics for suicide prevention.  Learning how to apply AI in healthcare proves to be a difficult task with many challenges, thus it remains rarely used as efforts to bridge gaps are deliberated. \\n\\n', 'source': 'https://en.wikipedia.org/wiki/Artificial_intelligence_in_mental_health'}),\n",
              " Document(page_content='In video games, artificial intelligence (AI) is used to generate responsive, adaptive or intelligent behaviors primarily in non-playable characters (NPCs) similar to human-like intelligence. Artificial intelligence has been an integral part of video games since their inception in the 1950s. AI in video games is a distinct subfield and differs from academic AI. It serves to improve the game-player experience rather than machine learning or decision making. During the golden age of arcade video games the idea of AI opponents was largely popularized in the form of graduated difficulty levels, distinct movement patterns, and in-game events dependent on the player\\'s input. Modern games often implement existing techniques such as pathfinding and decision trees to guide the actions of NPCs. AI is often used in mechanisms which are not immediately visible to the user, such as data mining and procedural-content generation.\\nIn general, game AI does not, as might be thought and sometimes is depicted to be the case, mean a realization of an artificial person corresponding to an NPC in the manner of the Turing test or an artificial general intelligence.\\n\\n\\n== Overview ==\\nThe term \"game AI\" is used to refer to a broad set of algorithms that also include techniques from control theory, robotics, computer graphics and computer science in general, and so video game AI may often not constitute \"true AI\" in that such techniques do not necessarily facilitate computer learning or other standard criteria, only constituting \"automated computation\" or a predetermined and limited set of responses to a predetermined and limited set of inputs.\\nMany industries and corporate voices argue that game AI has come a long way in the sense that it has revolutionized the way humans interact with all forms of technology, although many expert researchers are skeptical of such claims, and particularly of the notion that such technologies fit the definition of \"intelligence\" standardly used in the cognitive sciences. Industry voices make the argument that AI has become more versatile in the way we use all technological devices for more than their intended purpose because the AI allows the technology to operate in multiple ways, allegedly developing their own personalities and carrying out complex instructions of the user.\\nPeople in the field of AI have argued that video game AI is not true intelligence, but an advertising buzzword used to describe computer programs that use simple sorting and matching algorithms to create the illusion of intelligent behavior while bestowing software with a misleading aura of scientific or technological complexity and advancement. Since game AI for NPCs is centered on appearance of intelligence and good gameplay within environment restrictions, its approach is very different from that of traditional AI.\\n\\n\\n== History ==\\nGame playing was an area of research in AI from its inception. One of the first examples of AI is the computerized game of Nim made in 1951 and published in 1952. Despite being advanced technology in the year it was made, 20 years before Pong, the game took the form of a relatively small box and was able to regularly win games even against highly skilled players of the game. In 1951, using the Ferranti Mark 1 machine of the University of Manchester, Christopher Strachey wrote a checkers program and Dietrich Prinz wrote one for chess. These were among the first computer programs ever written. Arthur Samuel\\'s checkers program, developed in the middle 50s and early 60s, eventually achieved sufficient skill to challenge a respectable amateur. Work on checkers and chess would culminate in the defeat of Garry Kasparov by IBM\\'s Deep Blue computer in 1997. The first video games developed in the 1960s and early 1970s, like Spacewar!, Pong, and Gotcha (1973), were games implemented on discrete logic and strictly based on the competition of two players, without AI.\\nGames that featured a single player mode with enemies started appea', metadata={'title': 'Artificial intelligence in video games', 'summary': \"In video games, artificial intelligence (AI) is used to generate responsive, adaptive or intelligent behaviors primarily in non-playable characters (NPCs) similar to human-like intelligence. Artificial intelligence has been an integral part of video games since their inception in the 1950s. AI in video games is a distinct subfield and differs from academic AI. It serves to improve the game-player experience rather than machine learning or decision making. During the golden age of arcade video games the idea of AI opponents was largely popularized in the form of graduated difficulty levels, distinct movement patterns, and in-game events dependent on the player's input. Modern games often implement existing techniques such as pathfinding and decision trees to guide the actions of NPCs. AI is often used in mechanisms which are not immediately visible to the user, such as data mining and procedural-content generation.\\nIn general, game AI does not, as might be thought and sometimes is depicted to be the case, mean a realization of an artificial person corresponding to an NPC in the manner of the Turing test or an artificial general intelligence.\", 'source': 'https://en.wikipedia.org/wiki/Artificial_intelligence_in_video_games'}),\n",
              " Document(page_content='The artificial intelligence industry in China is a rapidly developing multi-billion dollar industry. The roots of China\\'s AI development started in the late 1970s following Deng Xiaoping\\'s economic reforms emphasizing science and technology as the country\\'s primary productive force.\\nThe initial stages of China\\'s AI development were slow and encountered significant challenges due to  lack of resources and talent. At the beginning China was behind most Western countries in terms of AI development. A majority of the research was led by scientists who had received higher education abroad.\\nSince 2006, the Chinese government has steadily developed a national agenda for artificial intelligence development and emerged as one of the leading nations in artificial intelligence research and development. In 2016, the Chinese Communist Party (CCP) released in its thirteenth five-year plan in which it aimed to become a global AI leader by 2030.\\nThe State Council has a list of \"national AI teams\" including fifteen China-based companies, including Baidu, Tencent, Alibaba, SenseTime, and iFlytek. Each company should lead the development of a designated specialized AI sector in China, such as facial recognition, software/hardware, and speech recognition. China\\'s rapid AI development has significantly impacted Chinese society in many areas, including the socio-economic, military, and political spheres. Agriculture, transportation, accommodation and food services, and manufacturing are the top industries that would be the most impacted by further AI deployment.\\nHowever, scholars have warned of potential negative impacts on China\\'s labor market and disproportionate benefits between urban and rural areas, coastal and inland regions, and among different income groups. The private sector, university laboratories, and the military are working collaboratively in many aspects as there are few current existing boundaries. In 2021, China published the Data Security Law of the People\\'s Republic of China, its first national law addressing AI-related ethical concerns. In October 2022, the United States federal government announced a series of export controls and trade restrictions intended to restrict China\\'s access to advanced computer chips for AI applications.\\nIn April 2023, the Cyberspace Administration of China issued draft measures stating that tech companies will be obligated to ensure AI-generated content upholds the ideology of the CCP including Core Socialist Values, avoids discrimination, respects intellectual property rights, and safeguards user data.:\\u200a278\\u200a Under these draft measures, companies bear legal responsibility for training data and content generated through their platforms.:\\u200a278\\u200a In October 2023, the Chinese government mandated that generative artificial intelligence-produced content may not \"incite subversion of state power or the overthrowing of the socialist system.\" Microsoft has warned that the Chinese government uses generative artificial intelligence to interfere in foreign elections by spreading disinformation and provoking discussions on divisive political issues.\\n\\n\\n== History ==\\nThe research and development of artificial intelligence in China started in the 1980s, with the announcement by Deng Xiaoping of the importance of science and technology for China\\'s economic growth.\\n\\n\\n=== Late 1970s to early 2010s ===\\nArtificial intelligence research and development did not start until the late 1970s after Deng Xiaoping\\'s economic reforms. While there was a lack of AI-related research between the 1950s and 1960s, some scholars believe this is due to the influence of cybernetics from the Soviet Union despite the Sino-Soviet split during the late 1950s and early 1960s. In the 1980s, a group of Chinese scientists launched AI research led by Qian Xuesen and Wu Wenjun. However, during the time, China\\'s society still had a generally conservative view towards AI. Early AI development in China was difficult so China\\'s government approached thes', metadata={'title': 'Artificial intelligence industry in China', 'summary': 'The artificial intelligence industry in China is a rapidly developing multi-billion dollar industry. The roots of China\\'s AI development started in the late 1970s following Deng Xiaoping\\'s economic reforms emphasizing science and technology as the country\\'s primary productive force.\\nThe initial stages of China\\'s AI development were slow and encountered significant challenges due to  lack of resources and talent. At the beginning China was behind most Western countries in terms of AI development. A majority of the research was led by scientists who had received higher education abroad.\\nSince 2006, the Chinese government has steadily developed a national agenda for artificial intelligence development and emerged as one of the leading nations in artificial intelligence research and development. In 2016, the Chinese Communist Party (CCP) released in its thirteenth five-year plan in which it aimed to become a global AI leader by 2030.\\nThe State Council has a list of \"national AI teams\" including fifteen China-based companies, including Baidu, Tencent, Alibaba, SenseTime, and iFlytek. Each company should lead the development of a designated specialized AI sector in China, such as facial recognition, software/hardware, and speech recognition. China\\'s rapid AI development has significantly impacted Chinese society in many areas, including the socio-economic, military, and political spheres. Agriculture, transportation, accommodation and food services, and manufacturing are the top industries that would be the most impacted by further AI deployment.\\nHowever, scholars have warned of potential negative impacts on China\\'s labor market and disproportionate benefits between urban and rural areas, coastal and inland regions, and among different income groups. The private sector, university laboratories, and the military are working collaboratively in many aspects as there are few current existing boundaries. In 2021, China published the Data Security Law of the People\\'s Republic of China, its first national law addressing AI-related ethical concerns. In October 2022, the United States federal government announced a series of export controls and trade restrictions intended to restrict China\\'s access to advanced computer chips for AI applications.\\nIn April 2023, the Cyberspace Administration of China issued draft measures stating that tech companies will be obligated to ensure AI-generated content upholds the ideology of the CCP including Core Socialist Values, avoids discrimination, respects intellectual property rights, and safeguards user data.:\\u200a278\\u200a Under these draft measures, companies bear legal responsibility for training data and content generated through their platforms.:\\u200a278\\u200a In October 2023, the Chinese government mandated that generative artificial intelligence-produced content may not \"incite subversion of state power or the overthrowing of the socialist system.\" Microsoft has warned that the Chinese government uses generative artificial intelligence to interfere in foreign elections by spreading disinformation and provoking discussions on divisive political issues.', 'source': 'https://en.wikipedia.org/wiki/Artificial_intelligence_industry_in_China'}),\n",
              " Document(page_content='ChatGPT is a chatbot and virtual assistant developed by OpenAI and launched on November 30, 2022. Based on large language models (LLMs), it enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. Successive user prompts and replies are considered at each conversation stage as context.\\nChatGPT is credited with starting the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence. By January 2023, it had become what was then the fastest-growing consumer software application in history, gaining over 100 million users and contributing to the growth of OpenAI\\'s current valuation of $86 billion. ChatGPT\\'s release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, based on OpenAI\\'s GPT-4. In June 2024, a partnership between Apple Inc. and OpenAI was announced in which ChatGPT is integrated into the Apple Intelligence feature of Apple operating systems. Some observers raised concern about the potential of ChatGPT and similar programs to displace or atrophy human intelligence, enable plagiarism, or fuel misinformation.\\nChatGPT is built on OpenAI\\'s proprietary series of generative pre-trained transformer (GPT) models and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o and GPT-3.5. The ChatGPT subscriptions \"Plus\", \"Team\" and \"Enterprise\" provide additional features such as DALL-E 3 image generation and increased GPT-4o usage limit.\\n\\n\\n== Training ==\\n\\nChatGPT is based on particular GPT foundation models, namely GPT-3.5, GPT-4, and GPT-4o, that were fine-tuned to target conversational usage. The fine-tuning process leveraged supervised learning and reinforcement learning from human feedback (RLHF). Both approaches employed human trainers to improve model performance. In the case of supervised learning, the trainers played both sides: the user and the AI assistant. In the reinforcement learning stage, human trainers first ranked responses that the model had created in a previous conversation. These rankings were used to create \"reward models\" that were used to fine-tune the model further by using several iterations of proximal policy optimization.\\nTime magazine revealed that to build a safety system against harmful content (e.g., sexual abuse, violence, racism, sexism), OpenAI used outsourced Kenyan workers earning less than $2 per hour to label harmful content. These labels were used to train a model to detect such content in the future. The outsourced laborers were exposed to \"toxic\" and traumatic content; one worker described the assignment as \"torture\". OpenAI\\'s outsourcing partner was Sama, a training-data company based in San Francisco, California.\\nChatGPT initially used a Microsoft Azure supercomputing infrastructure, powered by Nvidia GPUs, that Microsoft built specifically for OpenAI and that reportedly cost \"hundreds of millions of dollars\". Following ChatGPT\\'s success, Microsoft dramatically upgraded the OpenAI infrastructure in 2023. Scientists at the University of California, Riverside, estimate that a series of prompts to ChatGPT needs approximately 500 milliliters (18 imp fl oz; 17 U.S. fl oz) of water for Microsoft servers cooling. TrendForce market intelligence estimated that 30,000 Nvidia GPUs (each costing approximately $10,000–15,000) were used to power ChatGPT in 2023.\\nOpenAI collects data from ChatGPT users to train and fine-tune the service further. Users can upvote or downvote responses they receive from ChatGPT and fill in a text field with additional feedback.\\nChatGPT\\'s training data includes software manual pages, information about internet phenomena such as ', metadata={'title': 'ChatGPT', 'summary': 'ChatGPT is a chatbot and virtual assistant developed by OpenAI and launched on November 30, 2022. Based on large language models (LLMs), it enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. Successive user prompts and replies are considered at each conversation stage as context.\\nChatGPT is credited with starting the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence. By January 2023, it had become what was then the fastest-growing consumer software application in history, gaining over 100 million users and contributing to the growth of OpenAI\\'s current valuation of $86 billion. ChatGPT\\'s release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, based on OpenAI\\'s GPT-4. In June 2024, a partnership between Apple Inc. and OpenAI was announced in which ChatGPT is integrated into the Apple Intelligence feature of Apple operating systems. Some observers raised concern about the potential of ChatGPT and similar programs to displace or atrophy human intelligence, enable plagiarism, or fuel misinformation.\\nChatGPT is built on OpenAI\\'s proprietary series of generative pre-trained transformer (GPT) models and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o and GPT-3.5. The ChatGPT subscriptions \"Plus\", \"Team\" and \"Enterprise\" provide additional features such as DALL-E 3 image generation and increased GPT-4o usage limit.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/ChatGPT'}),\n",
              " Document(page_content='Gemini, formerly known as Bard, is a generative artificial intelligence chatbot developed by Google. Based on the large language model (LLM) of the same name and developed as a direct response to the meteoric rise of OpenAI\\'s ChatGPT, it was launched in a limited capacity in March 2023 before expanding to other countries in May. It was previously based on PaLM, and initially the LaMDA family of large language models.\\nLaMDA had been developed and announced in 2021, but it was not released to the public out of an abundance of caution. OpenAI\\'s launch of ChatGPT in November 2022 and its subsequent popularity caught Google executives off-guard and sent them into a panic, prompting a sweeping response in the ensuing months. After mobilizing its workforce, the company launched Bard in February 2023, which took center stage during the 2023 Google I/O keynote in May and was upgraded to the Gemini LLM in December. Bard and Duet AI were unified under the Gemini brand in February 2024, coinciding with the launch of an Android app.\\nGemini has received lukewarm responses. It became the center of controversy in February 2024, when social media users reported that it was generating historically inaccurate images of historical figures as people of color, with conservative commentators decrying its alleged bias as \"wokeness\".\\n\\n\\n== Background ==\\n\\nIn November 2022, OpenAI launched ChatGPT, a chatbot based on the GPT-3 family of large language models (LLMs). ChatGPT gained worldwide attention following its release, becoming a viral Internet sensation. Alarmed by ChatGPT\\'s potential threat to Google Search, Google executives issued a \"code red\" alert, reassigning several teams to assist in the company\\'s artificial intelligence (AI) efforts. Sundar Pichai, the CEO of Google and parent company Alphabet, was widely reported to have issued the alert, but Pichai later denied this to The New York Times. In a rare move, Google co-founders Larry Page and Sergey Brin, who had stepped down from their roles as co-CEOs of Alphabet in 2019, were summoned to emergency meetings with company executives to discuss Google\\'s response to ChatGPT. Brin requested access to Google\\'s code in February 2023, for the first time in years.\\nEarlier in 2021, the company had unveiled LaMDA, a prototype LLM, but did not release it to the public. When asked by employees at an all-hands meeting whether LaMDA was a missed opportunity for Google to compete with ChatGPT, Pichai and Google AI chief Jeff Dean stated that while the company had similar capabilities to ChatGPT, moving too quickly in that arena would represent a major \"reputational risk\" due to Google being substantially larger than OpenAI. In January 2023, Google sister company DeepMind CEO Demis Hassabis hinted at plans for a ChatGPT rival, and Google employees were instructed to accelerate progress on a ChatGPT competitor, intensively testing \"Apprentice Bard\" and other chatbots. Pichai assured investors during Google\\'s quarterly earnings investor call in February that the company had plans to expand LaMDA\\'s availability and applications.\\n\\n\\n== History ==\\n\\n\\n=== Announcement ===\\nOn February 6, 2023, Google announced Bard, a generative artificial intelligence chatbot powered by LaMDA. Bard was first rolled out to a select group of 10,000 \"trusted testers\", before a wide release scheduled at the end of the month. The project was overseen by product lead Jack Krawczyk, who described the product as a \"collaborative AI service\" rather than a search engine, while Pichai detailed how Bard would be integrated into Google Search. Reuters calculated that adding ChatGPT-like features to Google Search could cost the company $6 billion in additional expenses by 2024, while research and consulting firm SemiAnalysis calculated that it would cost Google $3 billion. The technology was developed under the codename \"Atlas\", with the name \"Bard\" in reference to the Celtic term for a storyteller and chosen to \"reflect the creative nature of th', metadata={'title': 'Gemini (chatbot)', 'summary': 'Gemini, formerly known as Bard, is a generative artificial intelligence chatbot developed by Google. Based on the large language model (LLM) of the same name and developed as a direct response to the meteoric rise of OpenAI\\'s ChatGPT, it was launched in a limited capacity in March 2023 before expanding to other countries in May. It was previously based on PaLM, and initially the LaMDA family of large language models.\\nLaMDA had been developed and announced in 2021, but it was not released to the public out of an abundance of caution. OpenAI\\'s launch of ChatGPT in November 2022 and its subsequent popularity caught Google executives off-guard and sent them into a panic, prompting a sweeping response in the ensuing months. After mobilizing its workforce, the company launched Bard in February 2023, which took center stage during the 2023 Google I/O keynote in May and was upgraded to the Gemini LLM in December. Bard and Duet AI were unified under the Gemini brand in February 2024, coinciding with the launch of an Android app.\\nGemini has received lukewarm responses. It became the center of controversy in February 2024, when social media users reported that it was generating historically inaccurate images of historical figures as people of color, with conservative commentators decrying its alleged bias as \"wokeness\".', 'source': 'https://en.wikipedia.org/wiki/Gemini_(chatbot)'}),\n",
              " Document(page_content='Music and artificial intelligence is the development of music software programs which use AI to generate music. As with applications in other fields, AI in music also simulates mental tasks. A prominent feature is the capability of an AI algorithm to learn based on past data, such as in computer accompaniment technology, wherein the AI is capable of listening to a human performer and performing accompaniment. Artificial intelligence also drives interactive composition technology, wherein a computer composes music in response to a live performance. There are other AI applications in music that cover not only music composition, production, and performance but also how music is marketed and consumed. Several music player programs have also been developed to use voice recognition and natural language processing technology for music voice control. Current research includes the application of AI in music composition, performance, theory and digital sound processing.\\nErwin Panofksy proposed that in all art, there existed 3 levels of meaning: primary meaning, or the natural subject; secondary meaning, or the conventional subject; and tertiary meaning, the intrinsic content of the subject. AI music explores the foremost of these, creating music without the \"intention\" which is usually behind it, leaving composers who listen to machine-generated pieces feeling unsettled by the lack of apparent meaning.\\n\\n\\n== History ==\\nArtificial intelligence finds its beginnings in music with the transcription problem: accurately recording a performance into musical notation as it is played. Père Engramelle\\'s schematic of a \"piano roll\", a mode of automatically recording note timing and duration in a way which could be easily transcribed to proper musical notation by hand, was first implemented by German engineers J.F. Unger and J. Hohlfield in 1752.\\nIn 1957, the ILLIAC I (Illinois Automatic Computer) produced the \"Illiac Suite for String Quartet\", a completely computer-generated piece of music. The computer was programmed to accomplish this by composer Lejaren Hiller and mathematician Leonard Isaacson.\\nIn 1960, Russian researcher Rudolf Zaripov published worldwide first paper on algorithmic music composing using the Ural-1 computer.\\nIn 1965, inventor Ray Kurzweil developed software capable of recognizing musical patterns and synthesizing new compositions from them. The computer first appeared on the quiz show I\\'ve Got a Secret.\\nBy 1983, Yamaha Corporation\\'s Kansei Music System had gained momentum, and a paper was published on its development in 1989. The software utilized music information processing and artificial intelligence techniques to essentially solve the transcription problem for simpler melodies, although higher-level melodies and musical complexities are regarded even today as difficult deep-learning tasks, and near-perfect transcription is still a subject of research.\\nIn 1997, an artificial intelligence program named Experiments in Musical Intelligence (EMI) appeared to outperform a human composer at the task of composing a piece of music to imitate the style of Bach. EMI would later become the basis for a more sophisticated algorithm called Emily Howell, named for its creator.\\nIn 2002, the music research team at the Sony Computer Science Laboratory Paris, led by French composer and scientist François Pachet, designed the Continuator, an algorithm uniquely capable of resuming a composition after a live musician stopped.\\nEmily Howell would continue to make advancements in musical artificial intelligence, publishing its first album From Darkness, Light in 2009, and its second album Breathless by 2012. Since then, many more pieces by artificial intelligence and various groups have been published.\\nIn 2010, Iamus became the first AI to produce a fragment of original contemporary classical music, in its own style: \"Iamus\\' Opus 1\". Located at the Universidad de Malága (Malága University) in Spain, the computer can generate a fully original piece i', metadata={'title': 'Music and artificial intelligence', 'summary': 'Music and artificial intelligence is the development of music software programs which use AI to generate music. As with applications in other fields, AI in music also simulates mental tasks. A prominent feature is the capability of an AI algorithm to learn based on past data, such as in computer accompaniment technology, wherein the AI is capable of listening to a human performer and performing accompaniment. Artificial intelligence also drives interactive composition technology, wherein a computer composes music in response to a live performance. There are other AI applications in music that cover not only music composition, production, and performance but also how music is marketed and consumed. Several music player programs have also been developed to use voice recognition and natural language processing technology for music voice control. Current research includes the application of AI in music composition, performance, theory and digital sound processing.\\nErwin Panofksy proposed that in all art, there existed 3 levels of meaning: primary meaning, or the natural subject; secondary meaning, or the conventional subject; and tertiary meaning, the intrinsic content of the subject. AI music explores the foremost of these, creating music without the \"intention\" which is usually behind it, leaving composers who listen to machine-generated pieces feeling unsettled by the lack of apparent meaning.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Music_and_artificial_intelligence'}),\n",
              " Document(page_content='\"BBL Drizzy\" (released as \"BBL DRIZZY BPM 150.mp3\") is an instrumental diss track by American record producer Metro Boomin. The track was released on May 5, 2024 dissing Drake in response to the Drake–Kendrick Lamar feud which consisted of multiple diss tracks from both sides. It samples a track, released on April 14th, of the same name by comedian King Willonius. It is the first notable example of AI sampling in mainstream hip-hop music, according to Billboard.\\nMetro announced he would offer a free beat and a $10,000 cash prize to whoever delivered the best rap over the backing track in an effort to deride hip hop artist Drake. The song\\'s title alludes to a rumor that Drake received a Brazilian butt lift, which is known as a \"BBL\" in modern slang.\\n\"BBL Drizzy\" quickly went viral, generating more than 3.3 million streams on SoundCloud within a week.\\n\\n\\n== Background ==\\n\\nThe Drake–Kendrick Lamar feud is an ongoing rap feud between American artist Kendrick Lamar and Canadian artist Drake which escalated in early 2024. Metro Boomin became closely involved in the feud after he, Lamar and Future released the song \"Like That\" in March 2024 which further escalated the conflict. In April 2024, Drake would release the song \"Push Ups\", in which he directly dismisses Metro\\'s involvement in the feud with the line \"Metro shut your hoe ass up and make some drums\". In the song \"Family Matters\", Drake further antagonizes Metro, directly calling him out in the song once again.\\nRick Ross coined the phrase BBL Drizzy, accusing Drake of receiving a Brazilian butt lift, a form of buttock augmentation surgery. Drake referred to Ross\\'s involvement in the feud in the song \"Push-Ups\" also, rapping: \"Can\\'t believe he jumpin\\' in, this nigga turnin\\' 50 / Every song that made it on the chart, he got from Drizzy / Spend that lil\\' check you got and stay up out my business\". Ross responded with his diss \"Champagne Moments\", coining the phrase BBL Drizzy on X (formerly known as Twitter) and Instagram while promoting the song. Inspired by an X post from Rick Ross, comedic performer Willonius Hatcher, who goes by King Willonius online, released an AI generated R&B parody song titled \"BBL Drizzy\". The song was created using Udio, a generative artificial intelligence model that produces music. Hatcher stated that he initially experimented with different music genres including country, Afrobeats and yacht rock before settling on R&B.\\n\\n\\n== Release ==\\nOn May 5, 2024, Metro responded to Drake\\'s diss on \"Family Matters\" on X and released an instrumental titled \"BBL DRIZZY 150 BPM.mp3\" on SoundCloud, sampling \"BBL Drizzy\", a comedic R&B song by King Willonius. Unbeknownst to Metro at the time, the original track\\'s vocals and instrumental were generated entirely by an artificial intelligence model. In addition to the release of the beat, Metro also announced that he would hold a contest on social media for whoever could produce the best freestyle rap over the beat, with the winner receiving a beat from him for free. Users on social media platforms including TikTok, Instagram and X were quick to react, releasing their own takes on the track shortly after. On May 6, Metro announced that he would also give the winner a $10,000 prize, and a runner-up would also receive a beat. Within a week, the song had received more than 3.3 million streams on SoundCloud and maintained the number one spot on the platform\\'s \"New and Hot\" chart. Metro has yet to pick a winner for the contest.\\n\\n\\n== Reception ==\\nUpon release, the track immediately received widespread attention on social media platforms. Notable celebrities and internet personalities including Elon Musk and Dr. Miami reacted to the beat. Several corporations also responded, including educational technology company Duolingo and meat producer Oscar Mayer.\\nIn addition to users releasing freestyle raps over the instrumental, the track also evolved into a viral phenomenon where users would create remixes of the song beyond the hip h', metadata={'title': 'BBL Drizzy', 'summary': '\"BBL Drizzy\" (released as \"BBL DRIZZY BPM 150.mp3\") is an instrumental diss track by American record producer Metro Boomin. The track was released on May 5, 2024 dissing Drake in response to the Drake–Kendrick Lamar feud which consisted of multiple diss tracks from both sides. It samples a track, released on April 14th, of the same name by comedian King Willonius. It is the first notable example of AI sampling in mainstream hip-hop music, according to Billboard.\\nMetro announced he would offer a free beat and a $10,000 cash prize to whoever delivered the best rap over the backing track in an effort to deride hip hop artist Drake. The song\\'s title alludes to a rumor that Drake received a Brazilian butt lift, which is known as a \"BBL\" in modern slang.\\n\"BBL Drizzy\" quickly went viral, generating more than 3.3 million streams on SoundCloud within a week.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/BBL_Drizzy'}),\n",
              " Document(page_content='Suno AI, or simply Suno, is a generative artificial intelligence music creation program designed to generate realistic songs that combine vocals and instrumentation, or are purely instrumental. Suno has been widely available since December 20, 2023, after the launch of a web application and a partnership with Microsoft, which included Suno as a plugin in Microsoft Copilot.\\n\\nThe program operates by producing songs based on text prompts provided by users. Suno does not disclose the dataset used to train its artificial intelligence but claims it has been safeguarded against plagiarism and copyright concerns.\\n\\n\\n== History ==\\nSuno was founded by four people: Michael Shulman, Georg Kucsko, Martin Camacho, and Keenan Freyberg. They all worked for Kensho, an AI startup, before starting their own company in Cambridge, Massachusetts.\\nIn April 2023, Suno released their open-source text-to-speech and audio model called \"Bark\" on GitHub and Hugging Face, under the MIT License. On March 21, 2024, Suno released its v3 version for all users. The new version allows users to create a limited number of 2-minute songs using a free account. Users can pay to subscribe monthly or annually to unlock more capabilities of Suno.\\n\\n\\n== See also ==\\nMusic and artificial intelligence\\nUdio\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nOfficial website', metadata={'title': 'Suno AI', 'summary': 'Suno AI, or simply Suno, is a generative artificial intelligence music creation program designed to generate realistic songs that combine vocals and instrumentation, or are purely instrumental. Suno has been widely available since December 20, 2023, after the launch of a web application and a partnership with Microsoft, which included Suno as a plugin in Microsoft Copilot.\\n\\nThe program operates by producing songs based on text prompts provided by users. Suno does not disclose the dataset used to train its artificial intelligence but claims it has been safeguarded against plagiarism and copyright concerns.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Suno_AI'}),\n",
              " Document(page_content='Artificial general intelligence (AGI) is a type of artificial intelligence (AI) that matches or surpasses human capabilities across a wide range of cognitive tasks. This is in contrast to narrow AI, which is designed for specific tasks. AGI is considered one of various definitions of strong AI.\\nCreating AGI is a primary goal of AI research and of companies such as OpenAI, DeepMind, and Anthropic. A 2020 survey identified 72 active AGI R&D projects spread across 37 countries.\\nThe timeline for achieving AGI remains a subject of ongoing debate among researchers and experts. As of 2023, some argue that it may be possible in years or decades; others maintain it might take a century or longer; and a minority believe it may never be achieved. There is debate on the exact definition of AGI, and regarding whether modern large language models (LLMs) such as GPT-4 are early, incomplete forms of AGI. AGI is a common topic in science fiction and futures studies.\\nContention exists over the potential for AGI to pose a threat to humanity; for example, OpenAI claims to treat it as an existential risk, while others find the development of AGI to be too remote to present a risk.\\n\\n\\n== Terminology ==\\nAGI is also known as strong AI, full AI, human-level AI or general intelligent action. However, some academic sources reserve the term \"strong AI\" for computer programs that experience sentience or consciousness. In contrast, weak AI (or narrow AI) is able to solve one specific problem, but lacks general cognitive abilities. Some academic sources use \"weak AI\" to refer more broadly to any programs that neither experience consciousness nor have a mind in the same sense as humans.\\nRelated concepts include artificial superintelligence and transformative AI. An artificial superintelligence (ASI) is a hypothetical type of AGI that is much more generally intelligent than humans, while the notion of transformative AI relates to AI having a large impact on society, for example, similar to the agricultural or industrial revolution.\\nA framework for classifying AGI in levels was proposed in 2023 by Google DeepMind researchers. They define five levels of AGI: emerging, competent, expert, virtuoso, and superhuman. For example, a competent AGI is defined as an AI that outperforms 50% of skilled adults in a wide range of non-physical tasks, and a superhuman AGI is similarly defined but with a threshold of 100%. They consider that large language models like ChatGPT or LLaMA 2 were instances or emerging AGI.\\n\\n\\n== Characteristics ==\\n\\nVarious criteria for intelligence have been proposed (most famously the Turing test) but no definition is broadly accepted.\\n\\n\\n=== Intelligence traits ===\\nHowever, researchers generally hold that intelligence is required to do all of the following:\\n\\nreason, use strategy, solve puzzles, and make judgments under uncertainty\\nrepresent knowledge, including common sense knowledge\\nplan\\nlearn\\ncommunicate in natural language\\nif necessary, integrate these skills in completion of any given goal\\nMany interdisciplinary approaches (e.g. cognitive science, computational intelligence, and decision making) consider additional traits such as imagination (the ability to form novel mental images and concepts) and autonomy.\\nComputer-based systems that exhibit many of these capabilities exist (e.g. see computational creativity, automated reasoning, decision support system, robot, evolutionary computation, intelligent agent). However, no consensus holds that modern AI systems possess them to an adequate degree.\\n\\n\\n=== Physical traits ===\\nOther capabilities are considered desirable in intelligent systems, as they may affect intelligence or aid in its expression. These include:\\n\\nthe ability to sense (e.g. see, hear, etc.), and\\nthe ability to act (e.g. move and manipulate objects, change location to explore, etc.)\\nThis includes the ability to detect and respond to hazard.\\n\\n\\n=== Tests for human-level AGI ===\\nSeveral tests meant to confirm human-level AGI have been co', metadata={'title': 'Artificial general intelligence', 'summary': 'Artificial general intelligence (AGI) is a type of artificial intelligence (AI) that matches or surpasses human capabilities across a wide range of cognitive tasks. This is in contrast to narrow AI, which is designed for specific tasks. AGI is considered one of various definitions of strong AI.\\nCreating AGI is a primary goal of AI research and of companies such as OpenAI, DeepMind, and Anthropic. A 2020 survey identified 72 active AGI R&D projects spread across 37 countries.\\nThe timeline for achieving AGI remains a subject of ongoing debate among researchers and experts. As of 2023, some argue that it may be possible in years or decades; others maintain it might take a century or longer; and a minority believe it may never be achieved. There is debate on the exact definition of AGI, and regarding whether modern large language models (LLMs) such as GPT-4 are early, incomplete forms of AGI. AGI is a common topic in science fiction and futures studies.\\nContention exists over the potential for AGI to pose a threat to humanity; for example, OpenAI claims to treat it as an existential risk, while others find the development of AGI to be too remote to present a risk.', 'source': 'https://en.wikipedia.org/wiki/Artificial_general_intelligence'}),\n",
              " Document(page_content='A generative adversarial network (GAN) is a class of machine learning frameworks and a prominent framework for approaching generative AI. The concept was initially developed by Ian Goodfellow and his colleagues in June 2014. In a GAN, two neural networks contest with each other in the form of a zero-sum game, where one agent\\'s gain is another agent\\'s loss.\\nGiven a training set, this technique learns to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of generative model for unsupervised learning, GANs have also proved useful for semi-supervised learning, fully supervised learning, and reinforcement learning.\\nThe core idea of a GAN is based on the \"indirect\" training through the discriminator, another neural network that can tell how \"realistic\" the input seems, which itself is also being updated dynamically. This means that the generator is not trained to minimize the distance to a specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner.\\nGANs are similar to mimicry in evolutionary biology, with an evolutionary arms race between both networks.\\n\\n\\n== Definition ==\\n\\n\\n=== Mathematical ===\\nThe original GAN is defined as the following game:\\nEach probability space \\n  \\n    \\n      \\n        (\\n        Ω\\n        ,\\n        \\n          μ\\n          \\n            ref\\n          \\n        \\n        )\\n      \\n    \\n    {\\\\displaystyle (\\\\Omega ,\\\\mu _{\\\\text{ref}})}\\n  \\n defines a GAN game.\\nThere are 2 players: generator and discriminator.\\nThe generator\\'s strategy set is \\n  \\n    \\n      \\n        \\n          \\n            P\\n          \\n        \\n        (\\n        Ω\\n        )\\n      \\n    \\n    {\\\\displaystyle {\\\\mathcal {P}}(\\\\Omega )}\\n  \\n, the set of all probability measures \\n  \\n    \\n      \\n        \\n          μ\\n          \\n            G\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mu _{G}}\\n  \\n on \\n  \\n    \\n      \\n        Ω\\n      \\n    \\n    {\\\\displaystyle \\\\Omega }\\n  \\n.\\nThe discriminator\\'s strategy set is the set of Markov kernels \\n  \\n    \\n      \\n        \\n          μ\\n          \\n            D\\n          \\n        \\n        :\\n        Ω\\n        →\\n        \\n          \\n            P\\n          \\n        \\n        [\\n        0\\n        ,\\n        1\\n        ]\\n      \\n    \\n    {\\\\displaystyle \\\\mu _{D}:\\\\Omega \\\\to {\\\\mathcal {P}}[0,1]}\\n  \\n, where \\n  \\n    \\n      \\n        \\n          \\n            P\\n          \\n        \\n        [\\n        0\\n        ,\\n        1\\n        ]\\n      \\n    \\n    {\\\\displaystyle {\\\\mathcal {P}}[0,1]}\\n  \\n is the set of probability measures on \\n  \\n    \\n      \\n        [\\n        0\\n        ,\\n        1\\n        ]\\n      \\n    \\n    {\\\\displaystyle [0,1]}\\n  \\n.\\nThe GAN game is a zero-sum game, with objective function\\nThe generator aims to minimize the objective, and the discriminator aims to maximize the objective.\\n\\nThe generator\\'s task is to approach \\n  \\n    \\n      \\n        \\n          μ\\n          \\n            G\\n          \\n        \\n        ≈\\n        \\n          μ\\n          \\n            ref\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle \\\\mu _{G}\\\\approx \\\\mu _{\\\\text{ref}}}\\n  \\n, that is, to match its own output distribution as closely as possible to the reference distribution. The discriminator\\'s task is to output a value close to 1 when the input appears to be from the reference distribution, and to output a value close to 0 when the input looks like it came from the generator distribution.\\n\\n\\n=== In practice ===\\nThe generative network generates candidates while the discriminative network evaluates them. The contest operates in terms of data distributions. Typically, the generative network learns to map from a latent space to a data distribution of interest, while the discriminative network distinguishes candidates produced by the generator from the true data distribution. The generative network\\'s training objec', metadata={'title': 'Generative adversarial network', 'summary': 'A generative adversarial network (GAN) is a class of machine learning frameworks and a prominent framework for approaching generative AI. The concept was initially developed by Ian Goodfellow and his colleagues in June 2014. In a GAN, two neural networks contest with each other in the form of a zero-sum game, where one agent\\'s gain is another agent\\'s loss.\\nGiven a training set, this technique learns to generate new data with the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of generative model for unsupervised learning, GANs have also proved useful for semi-supervised learning, fully supervised learning, and reinforcement learning.\\nThe core idea of a GAN is based on the \"indirect\" training through the discriminator, another neural network that can tell how \"realistic\" the input seems, which itself is also being updated dynamically. This means that the generator is not trained to minimize the distance to a specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner.\\nGANs are similar to mimicry in evolutionary biology, with an evolutionary arms race between both networks.', 'source': 'https://en.wikipedia.org/wiki/Generative_adversarial_network'}),\n",
              " Document(page_content='Artificial intelligence in healthcare is the application of artificial intelligence (AI) to copy human cognition in the analysis, presentation, and understanding of complex medical and health care data, or to exceed human capabilities by providing new ways to diagnose, treat, or prevent disease. Specifically, AI is the ability of computer algorithms to arrive at approximate conclusions based solely on input data.\\nThe primary aim of health-related AI applications is to analyze relationships between clinical data and patient outcomes. AI programs are applied to practices such as diagnostics, treatment protocol development, drug development, personalized medicine, and patient monitoring and care. What differentiates AI technology from traditional technologies in healthcare is the ability to gather larger and more diverse data, process it, and produce a well-defined output to the end-user. AI does this through machine learning algorithms and deep learning. Because radiographs are the most common imaging tests conducted in most radiology departments, the potential for AI to help with triage and interpretation of traditional radiographs (X-ray pictures) is particularly noteworthy. These processes can recognize patterns in behavior and create their own logic. To gain useful insights and predictions, machine learning models must be trained using extensive amounts of input data. AI algorithms behave differently from humans in two ways: (1) algorithms are literal: once a goal is set, the algorithm learns exclusively from the input data and can only understand what it has been programmed to do, (2) and some deep learning algorithms are black boxes; algorithms can predict with extreme precision, but offer little to no comprehensible explanation to the logic behind its decisions aside from the data and type of algorithm used.\\nAs widespread use of AI in healthcare is relatively new, research is ongoing into its application in various fields of medicine and industry. Additionally, greater consideration is being given to the unprecedented ethical concerns related to its practice such as data privacy, automation of jobs, and representation biases. Furthermore, new technologies brought about by AI in healthcare are often resisted by healthcare leaders, leading to slow and erratic adoption.\\nIn recent years, AI has played a leading role in the use and valuation of extensive collections of data, Google and the Mayo Clinic, for example, have  announced a partnership to solve complex medical problems using data-driven medical innovation, or a team from the University of California, San Diego was able to create a diagnostic program by training AI on medical records from 1.3 million patients under the age of 18.80 .\\n\\n\\n== History ==\\nResearch in the 1960s and 1970s produced the first problem-solving program, or expert system, known as Dendral. While it was designed for applications in organic chemistry, it provided the basis for a subsequent system MYCIN, considered one of the most significant early uses of artificial intelligence in medicine. MYCIN and other systems such as INTERNIST-1 and CASNET did not achieve routine use by practitioners, however.\\nThe 1980s and 1990s brought the proliferation of the microcomputer and new levels of network connectivity. During this time, there was a recognition by researchers and developers that AI systems in healthcare must be designed to accommodate the absence of perfect data and build on the expertise of physicians. Approaches involving fuzzy set theory, Bayesian networks, and artificial neural networks, have been applied to intelligent computing systems in healthcare.\\nMedical and technological advancements occurring over this half-century period that have enabled the growth of healthcare-related applications of AI to include: \\n\\nImprovements in computing power resulting in faster data collection and data processing\\nGrowth of genomic sequencing databases\\nWidespread implementation of electronic health record system', metadata={'title': 'Artificial intelligence in healthcare', 'summary': 'Artificial intelligence in healthcare is the application of artificial intelligence (AI) to copy human cognition in the analysis, presentation, and understanding of complex medical and health care data, or to exceed human capabilities by providing new ways to diagnose, treat, or prevent disease. Specifically, AI is the ability of computer algorithms to arrive at approximate conclusions based solely on input data.\\nThe primary aim of health-related AI applications is to analyze relationships between clinical data and patient outcomes. AI programs are applied to practices such as diagnostics, treatment protocol development, drug development, personalized medicine, and patient monitoring and care. What differentiates AI technology from traditional technologies in healthcare is the ability to gather larger and more diverse data, process it, and produce a well-defined output to the end-user. AI does this through machine learning algorithms and deep learning. Because radiographs are the most common imaging tests conducted in most radiology departments, the potential for AI to help with triage and interpretation of traditional radiographs (X-ray pictures) is particularly noteworthy. These processes can recognize patterns in behavior and create their own logic. To gain useful insights and predictions, machine learning models must be trained using extensive amounts of input data. AI algorithms behave differently from humans in two ways: (1) algorithms are literal: once a goal is set, the algorithm learns exclusively from the input data and can only understand what it has been programmed to do, (2) and some deep learning algorithms are black boxes; algorithms can predict with extreme precision, but offer little to no comprehensible explanation to the logic behind its decisions aside from the data and type of algorithm used.\\nAs widespread use of AI in healthcare is relatively new, research is ongoing into its application in various fields of medicine and industry. Additionally, greater consideration is being given to the unprecedented ethical concerns related to its practice such as data privacy, automation of jobs, and representation biases. Furthermore, new technologies brought about by AI in healthcare are often resisted by healthcare leaders, leading to slow and erratic adoption.\\nIn recent years, AI has played a leading role in the use and valuation of extensive collections of data, Google and the Mayo Clinic, for example, have  announced a partnership to solve complex medical problems using data-driven medical innovation, or a team from the University of California, San Diego was able to create a diagnostic program by training AI on medical records from 1.3 million patients under the age of 18.80 .\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Artificial_intelligence_in_healthcare'}),\n",
              " Document(page_content='The AI boom, or AI spring, is an ongoing period of rapid progress in the field of artificial intelligence (AI). Prominent examples include protein folding prediction led by Google DeepMind and generative AI led by OpenAI.\\n\\n\\n== History ==\\nIn 2012, a University of Toronto research team used artificial neural networks and deep learning techniques to lower the error rate below 25% for the first time during the ImageNet challenge for object recognition in computer vision. The event catalyzed the AI boom later that decade, when many alumni of the ImageNet challenge became leaders in the tech industry. The generative AI race began in earnest in 2016 or 2017 following the founding of OpenAI and earlier advances made in graphical processing units, the amount and quality of training data, generative adversarial networks, diffusion models and transformer architectures. In 2018, the Artificial Intelligence Index, an initiative from Stanford University, reported a global explosion of commercial and research efforts in AI. Europe published the largest number of papers in the field that year, followed by China and North America. Technologies such as AlphaFold led to more accurate predictions of protein folding and improved the process of drug development. Economists and lawmakers began to discuss the potential impact of AI more frequently. By 2022, large language models saw increased usage in chatbot applications; text-to-image-models could generate images that appeared to be human-made; and speech synthesis software was able to replicate human speech efficiently.\\nAccording to metrics from 2017 to 2021, the United States outranks the rest of the world in terms of venture capital funding, the number of startups, and patents granted in AI. Scientists who have immigrated to the U.S. play an outsize role in the country\\'s development of AI technology. Many of them were educated in China, prompting debates about national security concerns amid worsening relations between the two countries.\\nExperts have framed AI development as a competition for economic and geopolitical advantage between the United States and China. In 2021, an analyst for the Council on Foreign Relations outlined ways that the U.S. could maintain its position amid progress made by China. In 2023, an analyst at the Center for Strategic and International Studies advocated for the U.S. to use its dominance in AI technology to drive its foreign policy instead of relying on trade agreements.\\n\\n\\n== Advances ==\\n\\n\\n=== Biomedical ===\\nThere have been proposals to use AI to advance radical forms of human life extension.\\nThe AlphaFold 2 score of more than 90 in CASP\\'s global distance test (GDT) is considered a significant achievement in computational biology and great progress towards a decades-old grand challenge of biology. Nobel Prize winner and structural biologist Venki Ramakrishnan called the result \"a stunning advance on the protein folding problem\", adding that \"It has occurred decades before many people in the field would have predicted.\"\\nThe ability to predict protein structures accurately based on the constituent amino acid sequence is expected to accelerate drug discovery and enable a better understanding of diseases. It went on to note that the AI algorithm could \"predict the shape of proteins to within the width of an atom.\"\\n\\n\\n=== Images and videos ===\\n\\nText-to-image models captured widespread public attention when OpenAI announced DALL-E, a transformer system, in January 2021. A successor capable of generating complex and realistic images, DALL-E 2, was unveiled in April 2022. An alternative text-to-image model, Midjourney, was released in July 2022. Another alternative, open-source model Stable Diffusion, released in August 2022.\\nFollowing other text-to-image models, language model-powered text-to-video platforms such as OpenAI\\'s Sora, DAMO, Make-A-Video, Imagen Video and Phenaki can generate video from text as well as image prompts.\\n\\n\\n=== Language ===\\nGPT-3 is a large languag', metadata={'title': 'AI boom', 'summary': 'The AI boom, or AI spring, is an ongoing period of rapid progress in the field of artificial intelligence (AI). Prominent examples include protein folding prediction led by Google DeepMind and generative AI led by OpenAI.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/AI_boom'}),\n",
              " Document(page_content='Generative art is post-conceptual art that has been created (in whole or in part) with the use of an autonomous system. An autonomous system in this context is generally one that is non-human and can independently determine features of an artwork that would otherwise require decisions made directly by the artist. In some cases the human creator may claim that the generative system represents their own artistic idea, and in others that the system takes on the role of the creator.\\n\"Generative art\" often refers to algorithmic art (algorithmically determined computer generated artwork) and synthetic media (general term for any algorithmically generated media), but artists can also make generative art using systems of chemistry, biology, mechanics and robotics, smart materials, manual randomization, mathematics, data mapping, symmetry, and tiling.\\n\\n\\n== History ==\\nThe use of the word \"generative\" in the discussion of art has developed over time. The use of \"Artificial DNA\" defines a generative approach to art focused on the construction of a system able to generate unpredictable events, all with a recognizable common character. The use of autonomous systems, required by some contemporary definitions, focuses a generative approach where the controls are strongly reduced. This approach is also named \"emergent\". Margaret Boden and Ernest Edmonds have noted the use of the term \"generative art\" in the broad context of automated computer graphics in the 1960s, beginning with artwork exhibited by Georg Nees and Frieder Nake in 1965: A. Michael Noll did his initial computer art, combining randomness with order, in 1962, and exhibited it along with works by Bell Julesz in 1965.\\n\\n  The  terms  \"generative art\"  and  \"computer  art\"  have been  used  in  tandem,  and  more  or  less interchangeably, since the very earliest days.\\nThe first such exhibition showed the work of Nees in February 1965, which some claim was titled \"Generative Computergrafik\". While Nees does not himself remember, this was the title of his doctoral thesis published a few years later. The correct title of the first exhibition and catalog was \"computer-grafik\". \"Generative art\" and related terms was in common use by several other early computer artists around this time, including Manfred Mohr and Ken Knowlton. Vera Molnár (born 1924) is a French media artist of Hungarian origin. Molnar is widely considered to be a pioneer of generative art, and is also one of the first women to use computers in her art practice. \\nThe term \"Generative Art\" with the meaning of dynamic artwork-systems able to generate multiple artwork-events was clearly used the first time for the \"Generative Art\" conference in Milan in 1998. The term has also been used to describe geometric abstract art where simple elements are repeated, transformed, or varied to generate more complex forms. Thus defined, generative art was practiced by the Argentinian artists Eduardo Mac Entyre and Miguel Ángel Vidal in the late 1960s. In 1972 the Romanian-born Paul Neagu created the Generative Art Group in Britain. It was populated exclusively by Neagu using aliases such as \"Hunsy Belmood\" and \"Edward Larsocchi\". In 1972 Neagu gave a lecture titled \\'Generative Art Forms\\' at the Queen\\'s University, Belfast Festival.\\nIn 1970 the School of the Art Institute of Chicago created a department called  Generative Systems. As described by Sonia Landy Sheridan the focus was on art practices using the then new technologies for the capture, inter-machine transfer, printing and transmission of images, as well as the exploration of the aspect of time in the transformation of image information. Also noteworthy is John Dunn,  first a student and then a collaborator of Sheridan.\\nIn 1988 Clauser identified the aspect of systemic autonomy as a critical element in generative art:\\n\\n  It should be evident from the above description of the evolution of generative art that process (or structuring) and change (or transformation) are among its mo', metadata={'title': 'Generative art', 'summary': 'Generative art is post-conceptual art that has been created (in whole or in part) with the use of an autonomous system. An autonomous system in this context is generally one that is non-human and can independently determine features of an artwork that would otherwise require decisions made directly by the artist. In some cases the human creator may claim that the generative system represents their own artistic idea, and in others that the system takes on the role of the creator.\\n\"Generative art\" often refers to algorithmic art (algorithmically determined computer generated artwork) and synthetic media (general term for any algorithmically generated media), but artists can also make generative art using systems of chemistry, biology, mechanics and robotics, smart materials, manual randomization, mathematics, data mapping, symmetry, and tiling.', 'source': 'https://en.wikipedia.org/wiki/Generative_art'}),\n",
              " Document(page_content='This glossary of artificial intelligence is a list of definitions of terms and concepts relevant to the study of artificial intelligence, its sub-disciplines, and related fields. Related glossaries include Glossary of computer science, Glossary of robotics, and Glossary of machine vision.\\n\\n\\n== A ==\\n\\nabductive logic programming (ALP)\\nA high-level knowledge-representation framework that can be used to solve problems declaratively based on abductive reasoning. It extends normal logic programming by allowing some predicates to be incompletely defined, declared as abducible predicates.\\n\\nabductive reasoning\\nAlso abduction.\\nA form of logical inference which starts with an observation or set of observations then seeks to find the simplest and most likely explanation. This process, unlike deductive reasoning, yields a plausible conclusion but does not positively verify it. abductive inference, or retroduction\\n\\nabstract data type\\nA mathematical model for data types, where a data type is defined by its behavior (semantics) from the point of view of a user of the data, specifically in terms of possible values, possible operations on data of this type, and the behavior of these operations.\\n\\nabstraction\\nThe process of removing physical, spatial, or temporal details or attributes in the study of objects or systems in order to more closely attend to other details of interest\\n\\naccelerating change\\nA perceived increase in the rate of technological change throughout history, which may suggest faster and more profound change in the future and may or may not be accompanied by equally profound social and cultural change.\\n\\naction language\\nA language for specifying state transition systems, and is commonly used to create formal models of the effects of actions on the world. Action languages are commonly used in the artificial intelligence and robotics domains, where they describe how actions affect the states of systems over time, and may be used for automated planning.\\n\\naction model learning\\nAn area of machine learning concerned with creation and modification of software agent\\'s knowledge about effects and preconditions of the actions that can be executed within its environment. This knowledge is usually represented in logic-based action description language and used as the input for automated planners.\\n\\naction selection\\nA way of characterizing the most basic problem of intelligent systems: what to do next. In artificial intelligence and computational cognitive science, \"the action selection problem\" is typically associated with intelligent agents and animats—artificial systems that exhibit complex behaviour in an agent environment.\\n\\nactivation function\\nIn artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs.\\n\\nadaptive algorithm\\nAn algorithm that changes its behavior at the time it is run, based on a priori defined reward mechanism or criterion.\\n\\nadaptive neuro fuzzy inference system (ANFIS)\\nAlso adaptive network-based fuzzy inference system.\\nA kind of artificial neural network that is based on Takagi–Sugeno fuzzy inference system. The technique was developed in the early 1990s. Since it integrates both neural networks and fuzzy logic principles, it has potential to capture the benefits of both in a single framework. Its inference system corresponds to a set of fuzzy IF–THEN rules that have learning capability to approximate nonlinear functions. Hence, ANFIS is considered to be a universal estimator. For using the ANFIS in a more efficient and optimal way, one can use the best parameters obtained by genetic algorithm.\\n\\nadmissible heuristic\\nIn computer science, specifically in algorithms related to pathfinding, a heuristic function is said to be admissible if it never overestimates the cost of reaching the goal, i.e. the cost it estimates to reach the goal is not higher than the lowest possible cost from the current point in the path.\\n\\naffective computing\\nAlso artificial emotiona', metadata={'title': 'Glossary of artificial intelligence', 'summary': 'This glossary of artificial intelligence is a list of definitions of terms and concepts relevant to the study of artificial intelligence, its sub-disciplines, and related fields. Related glossaries include Glossary of computer science, Glossary of robotics, and Glossary of machine vision.', 'source': 'https://en.wikipedia.org/wiki/Glossary_of_artificial_intelligence'}),\n",
              " Document(page_content='robots.txt is the filename used for implementing the Robots Exclusion Protocol, a standard used by websites to indicate to visiting web crawlers and other web robots which portions of the website they are allowed to visit.\\nThe standard, developed in 1994, relies on voluntary compliance. Malicious bots can use the file as a directory of which pages to visit, though standards bodies discourage countering this with security through obscurity. Some archival sites ignore robots.txt. The standard was used in the 1990s to mitigate server overload; in the 2020s many websites began denying bots that collect information for generative artificial intelligence.\\nThe \"robots.txt\" file can be used in conjunction with sitemaps, another robot inclusion standard for websites.\\n\\n\\n== History ==\\nThe standard was proposed by Martijn Koster, when working for Nexor in February 1994 on the www-talk mailing list, the main communication channel for WWW-related activities at the time. Charles Stross claims to have provoked Koster to suggest robots.txt, after he wrote a badly behaved web crawler that inadvertently caused a denial-of-service attack on Koster\\'s server.\\nThe standard, initially RobotsNotWanted.txt, allowed web developers to specify which bots should not access their website or which pages bots should not access. The internet was small enough in 1994 to maintain a complete list of all bots; server overload was a primary concern. By June 1994 it had become a de facto standard; most complied, including those operated by search engines such as WebCrawler, Lycos, and AltaVista.\\nOn July 1, 2019, Google announced the proposal of the Robots Exclusion Protocol as an official standard under Internet Engineering Task Force. A proposed standard was published in September 2022 as RFC 9309.\\n\\n\\n== Standard ==\\nWhen a site owner wishes to give instructions to web robots they place a text file called robots.txt in the root of the web site hierarchy (e.g. https://www.example.com/robots.txt). This text file contains the instructions in a specific format (see examples below). Robots that choose to follow the instructions try to fetch this file and read the instructions before fetching any other file from the website. If this file does not exist, web robots assume that the website owner does not wish to place any limitations on crawling the entire site.\\nA robots.txt file contains instructions for bots indicating which web pages they can and cannot access. Robots.txt files are particularly important for web crawlers from search engines such as Google.\\nA robots.txt file on a website will function as a request that specified robots ignore specified files or directories when crawling a site. This might be, for example, out of a preference for privacy from search engine results, or the belief that the content of the selected directories might be misleading or irrelevant to the categorization of the site as a whole, or out of a desire that an application only operates on certain data. Links to pages listed in robots.txt can still appear in search results if they are linked to from a page that is crawled.\\nA robots.txt file covers one origin. For websites with multiple subdomains, each subdomain must have its own robots.txt file. If example.com had a robots.txt file but a.example.com did not, the rules that would apply for example.com would not apply to a.example.com. In addition, each protocol and port needs its own robots.txt file; http://example.com/robots.txt does not apply to pages under http://example.com:8080/ or https://example.com/.\\n\\n\\n== Compliance ==\\nA robots.txt has no enforcement mechanism in law or in technical protocol, despite widespread compliance by bot operators.\\n\\n\\n=== Search engines ===\\nSome major search engines following this standard include Ask, AOL, Baidu, Bing,  DuckDuckGo, Google, Yahoo!, and Yandex. \\n\\n\\n=== Archival sites ===\\nSome web archiving projects ignore robots.txt. Archive Team uses the file to discover more links, such as sitemaps. Co-founde', metadata={'title': 'Robots.txt', 'summary': 'robots.txt is the filename used for implementing the Robots Exclusion Protocol, a standard used by websites to indicate to visiting web crawlers and other web robots which portions of the website they are allowed to visit.\\nThe standard, developed in 1994, relies on voluntary compliance. Malicious bots can use the file as a directory of which pages to visit, though standards bodies discourage countering this with security through obscurity. Some archival sites ignore robots.txt. The standard was used in the 1990s to mitigate server overload; in the 2020s many websites began denying bots that collect information for generative artificial intelligence.\\nThe \"robots.txt\" file can be used in conjunction with sitemaps, another robot inclusion standard for websites.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Robots.txt'}),\n",
              " Document(page_content='The ethics of artificial intelligence covers a broad range of topics within the field that are considered to have particular ethical stakes. This includes algorithmic biases, fairness, automated decision-making, accountability, privacy, and regulation. \\nIt also covers various emerging or potential future challenges such as machine ethics (how to make machines that behave ethically), lethal autonomous weapon systems, arms race dynamics, AI safety and alignment, technological unemployment, AI-enabled misinformation, how to treat certain AI systems if they have a moral status (AI welfare and rights), artificial superintelligence and existential risks. \\nSome application areas may also have particularly important ethical implications, like healthcare, education, criminal justice, or the military.\\n\\n\\n== Machine ethics ==\\n\\nMachine ethics (or machine morality) is the field of research concerned with designing Artificial Moral Agents (AMAs), robots or artificially intelligent computers that behave morally or as though moral. To account for the nature of these agents, it has been suggested to consider certain philosophical ideas, like the standard characterizations of agency, rational agency, moral agency, and artificial agency, which are related to the concept of AMAs.\\nThere are discussions on creating tests to see if an AI is capable of making ethical decisions. Alan Winfield concludes that the Turing test is flawed and the requirement for an AI to pass the test is too low. A proposed alternative test is one called the Ethical Turing Test, which would improve on the current test by having multiple judges decide if the AI\\'s decision is ethical or unethical. Neuromorphic AI could be one way to create morally capable robots, as it aims to process information similarly to humans, nonlinearly and with millions of interconnected artificial neurons. Similarly, whole-brain emulation (scanning a brain and simulating it on digital hardware) could also in principle lead to human-like robots, thus capable of moral actions. And large language models are capable of approximating human moral judgments. Inevitably, this raises the question of the environment in which such robots would learn about the world and whose morality they would inherit – or if they end up developing human \\'weaknesses\\' as well: selfishness, pro-survival attitudes, inconsistency, scale insensitivity, etc.\\nIn Moral Machines: Teaching Robots Right from Wrong, Wendell Wallach and Colin Allen conclude that attempts to teach robots right from wrong will likely advance understanding of human ethics by motivating humans to address gaps in modern normative theory and by providing a platform for experimental investigation. As one example, it has introduced normative ethicists to the controversial issue of which specific learning algorithms to use in machines. For simple decisions, Nick Bostrom and Eliezer Yudkowsky have argued that decision trees (such as ID3) are more transparent than neural networks and genetic algorithms, while Chris Santos-Lang argued in favor of machine learning on the grounds that the norms of any age must be allowed to change and that natural failure to fully satisfy these particular norms has been essential in making humans less vulnerable to criminal \"hackers\".\\n\\n\\n=== Robot ethics ===\\n\\nThe term \"robot ethics\" (sometimes \"roboethics\") refers to the morality of how humans design, construct, use and treat robots. Robot ethics intersect with the ethics of AI. Robots are physical machines whereas AI can be only software. Not all robots function through AI systems and not all AI systems are robots. Robot ethics considers how machines may be used to harm or benefit humans, their impact on individual autonomy, and their effects on social justice.\\n\\n\\n=== Ethical principles ===\\nIn the review of 84 ethics guidelines for AI, 11 clusters of principles were found: transparency, justice and fairness, non-maleficence, responsibility, privacy, beneficence, freedom and autonomy, tr', metadata={'title': 'Ethics of artificial intelligence', 'summary': 'The ethics of artificial intelligence covers a broad range of topics within the field that are considered to have particular ethical stakes. This includes algorithmic biases, fairness, automated decision-making, accountability, privacy, and regulation. \\nIt also covers various emerging or potential future challenges such as machine ethics (how to make machines that behave ethically), lethal autonomous weapon systems, arms race dynamics, AI safety and alignment, technological unemployment, AI-enabled misinformation, how to treat certain AI systems if they have a moral status (AI welfare and rights), artificial superintelligence and existential risks. \\nSome application areas may also have particularly important ethical implications, like healthcare, education, criminal justice, or the military.', 'source': 'https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence'}),\n",
              " Document(page_content='Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and uses learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\\nAI technology is widely used throughout industry, government, and science. Some high-profile applications include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nAlan Turing was the first person to conduct substantial research in the field that he called machine intelligence. Artificial intelligence was founded as an academic discipline in 1956. The field went through multiple cycles of optimism, followed by periods of disappointment and loss of funding, known as AI winter. Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques, and after 2017 with the transformer architecture. This led to the AI boom of the early 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant advances in artificial intelligence.\\nThe growing use of artificial intelligence in the 21st century is influencing a societal and economic shift towards increased automation, data-driven decision-making, and the integration of AI systems into various economic sectors and areas of life, impacting job markets, healthcare, government, industry, education, propaganda, and disinformation. This raises questions about the long-term effects, ethical implications, and risks of AI, prompting discussions about regulatory policies to ensure the safety and benefits of the technology. \\nThe various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performable by a human on an at least equal level—is among the field\\'s long-term goals.\\nTo reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\\n\\n\\n== Goals ==\\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.\\n\\n\\n=== Reasoning and problem-solving ===\\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions. By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.\\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow. Even humans rarely use the step-by-step deduction that early AI research co', metadata={'title': 'Artificial intelligence', 'summary': 'Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and uses learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\\nAI technology is widely used throughout industry, government, and science. Some high-profile applications include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"\\nAlan Turing was the first person to conduct substantial research in the field that he called machine intelligence. Artificial intelligence was founded as an academic discipline in 1956. The field went through multiple cycles of optimism, followed by periods of disappointment and loss of funding, known as AI winter. Funding and interest vastly increased after 2012 when deep learning surpassed all previous AI techniques, and after 2017 with the transformer architecture. This led to the AI boom of the early 2020s, with companies, universities, and laboratories overwhelmingly based in the United States pioneering significant advances in artificial intelligence.\\nThe growing use of artificial intelligence in the 21st century is influencing a societal and economic shift towards increased automation, data-driven decision-making, and the integration of AI systems into various economic sectors and areas of life, impacting job markets, healthcare, government, industry, education, propaganda, and disinformation. This raises questions about the long-term effects, ethical implications, and risks of AI, prompting discussions about regulatory policies to ensure the safety and benefits of the technology. \\nThe various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performable by a human on an at least equal level—is among the field\\'s long-term goals.\\nTo reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.', 'source': 'https://en.wikipedia.org/wiki/Artificial_intelligence'}),\n",
              " Document(page_content='Grok is a generative artificial intelligence chatbot developed by xAI. Based on a large language model (LLM), it was developed as an initiative by Elon Musk in a direct response to the meteoric rise of ChatGPT, the developer of which, OpenAI, Musk co-founded. The chatbot is advertised as \"having a sense of humor\" and direct access to X. It is currently under beta testing and is available with X Premium.\\n\\n\\n== Background ==\\nMusk co-founded the AI research organization OpenAI with Sam Altman in 2015. Musk left the company\\'s board in 2018, saying of his decision that he \"didn\\'t agree with some of what OpenAI team wanted to do\". OpenAI went on to launch ChatGPT in 2022, and GPT-4 in March 2023. That month, Elon Musk was one of individuals to sign an open letter from the Future of Life Institute calling for a six-month pause in the development of any AI software more powerful than GPT-4.\\nIn April 2023, Elon Musk said in an interview on Tucker Carlson Tonight that he intended to develop an AI chatbot called \"TruthGPT\", which he described as \"a maximum truth-seeking AI that tries to understand the nature of the universe\". He expressed concern to Carlson that ChatGPT was being \"trained to be politically correct\".\\nTruthGPT would later become known as \"Grok\", a verb coined by Robert A. Heinlein in his 1961 science-fiction novel Stranger in a Strange Land to describe a form of understanding.\\n\\n\\n== History ==\\nIn November 2023, xAI began previewing Grok as a chatbot to selected people, with participation in the early access program being limited to paid X Premium users. It was announced that once the bot was out of early beta, it would only be available to higher tier X Premium+ subscribers. At the time of the preview, xAI described the chatbot as \"a very early beta product – the best we could do with 2 months of training\" that could \"improve rapidly with each passing week\".\\nIn December 2023 the Silicon Valley start-up Curio launched a range of AI-powered children\\'s toys, including a rocket-shaped character named Grok. The toy is voiced by Musk\\'s ex-girlfriend Grimes, who is also an investor in the start-up, but the product is unrelated to the xAI service.\\nOn March 11, 2024, Musk posted on X that the language model would go open source within a week and six days later, on March 17, Grok became partially open source. Disclosed were the networks architecture and its weight parameters.\\nOn March 17, 2024, Grok-1 was open sourced under the Apache-2.0 license.\\nOn March 26, 2024, Musk announced that Grok would be enabled for all premium subscribers, not just those on the higher-end tier, Premium+.\\nOn March 29, 2024, Grok-1.5 was announced, with \"improved reasoning capabilities\" and a context length of 128,000 tokens. \\nOn April 4, 2024, an update to X\\'s \"Explore\" page included summaries of breaking news stories written by Grok, a task previously assigned to a human curation team.\\nOn April 12, 2024, Grok-1.5 Vision (Grok-1.5V) was announced. Grok-1.5V is able to process a wide variety of visual information, including documents, diagrams, graphs, screenshots, and photographs.\\nOn May 4, 2024, Grok became available in the United Kingdom, being the only country in Europe to support Grok at the moment due to the impending  Artificial Intelligence Act rules in the European Union. Grok was later reviewed by the EU and was released on May 16, 2024.\\n\\n\\n== Features ==\\n\\n\\n=== Humor ===\\nAn xAI statement described the chatbot as having been designed to \"answer questions with a bit of wit\" and as having \"a rebellious streak\". It said that bot had been \"modeled after The Hitchhiker\\'s Guide to the Galaxy, so intended to answer almost anything\".\\nAn extract shared by an X employee showed Grok being asked to answer the question \"When is it appropriate to listen to Christmas music?\" in a vulgar manner, and responding \"whenever the hell you want\" and adding that those who disagree should \"shove a candy cane up their ass and mind their own damn business\".\\nThe chatbot defaul', metadata={'title': 'Grok (chatbot)', 'summary': 'Grok is a generative artificial intelligence chatbot developed by xAI. Based on a large language model (LLM), it was developed as an initiative by Elon Musk in a direct response to the meteoric rise of ChatGPT, the developer of which, OpenAI, Musk co-founded. The chatbot is advertised as \"having a sense of humor\" and direct access to X. It is currently under beta testing and is available with X Premium.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Grok_(chatbot)'})]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a418432",
      "metadata": {
        "id": "1a418432"
      },
      "source": [
        "# Content Retrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76a19668",
      "metadata": {
        "id": "76a19668",
        "outputId": "08388066-6aaf-4748-fb89-71bb8e14bfb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generative artificial intelligence (generative AI, GenAI, or GAI) is artificial intelligence capable of generating text, images, videos, or other data using generative models, often in response to prompts. Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.\n",
            "Improvements in transformer-based deep neural networks\n"
          ]
        }
      ],
      "source": [
        "meta_data = documents[0].metadata\n",
        "\n",
        "excerpts = [doc.page_content[:404] for doc in documents]\n",
        "\n",
        "print(excerpts[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e85b076f",
      "metadata": {
        "id": "e85b076f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}